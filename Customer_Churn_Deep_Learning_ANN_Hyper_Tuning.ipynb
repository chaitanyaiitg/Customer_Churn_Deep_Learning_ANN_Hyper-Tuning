{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Customer_Churn_Deep_Learning_ANN_Hyper Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iig0a3Sbm2i",
        "outputId": "2cb8f566-fa61-4c78-91c5-9f692cbf47d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        }
      },
      "source": [
        "! pip install tensorflow-gpu"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.3.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.35.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.7.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (50.3.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (1.17.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu) (3.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLuJ3IyBbzUk",
        "outputId": "fb0797ab-78f0-4343-df5b-3120042bbcff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "! pip install keras"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBH6WN3Db5qw",
        "outputId": "156047f9-50c1-4dcf-e65f-de632c80cfaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "! pip install pandas"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-V_R6PhRy3Z"
      },
      "source": [
        "Customer Churn Prediction Using Artificial Neural Network (ANN)\n",
        "Customer churn prediction is to measure why customers are leaving a business. In this tutorial we will be looking at customer churn in telecom business. We will build a deep learning model to predict the churn and use precision,recall, f1-score to measure performance of our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPqXRMj_b5wC",
        "outputId": "0a1300bf-a712-49bb-c05c-de92712e5132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"Hub version:\", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version: 2.3.1\n",
            "Hub version: 0.9.0\n",
            "WARNING:tensorflow:From <ipython-input-32-c62ce35fd0be>:7: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izjchs6sb51O"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D,MaxPooling2D\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, LeakyReLU, BatchNormalization, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
        "from tensorflow.keras.models import Sequential\n",
        "from glob import glob\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgdvwuWPb56c"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBNVQkSVb5_d",
        "outputId": "f3142308-264f-42b0-c69e-9d2b594934f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBYFY4Pbb6E2"
      },
      "source": [
        "file=\"/content/drive/My Drive/Colab Notebooks/Churn_Modelling.csv\"\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUPoix_vb6KO",
        "outputId": "c8d18fe6-353e-4743-c365-125aae1e3d31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(file)\n",
        "df"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9996</td>\n",
              "      <td>15606229</td>\n",
              "      <td>Obijiaku</td>\n",
              "      <td>771</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>15569892</td>\n",
              "      <td>Johnstone</td>\n",
              "      <td>516</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>15584532</td>\n",
              "      <td>Liu</td>\n",
              "      <td>709</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>15682355</td>\n",
              "      <td>Sabbatini</td>\n",
              "      <td>772</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Male</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>15628319</td>\n",
              "      <td>Walker</td>\n",
              "      <td>792</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      RowNumber  CustomerId    Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0             1    15634602   Hargrave  ...               1       101348.88      1\n",
              "1             2    15647311       Hill  ...               1       112542.58      0\n",
              "2             3    15619304       Onio  ...               0       113931.57      1\n",
              "3             4    15701354       Boni  ...               0        93826.63      0\n",
              "4             5    15737888   Mitchell  ...               1        79084.10      0\n",
              "...         ...         ...        ...  ...             ...             ...    ...\n",
              "9995       9996    15606229   Obijiaku  ...               0        96270.64      0\n",
              "9996       9997    15569892  Johnstone  ...               1       101699.77      0\n",
              "9997       9998    15584532        Liu  ...               1        42085.58      1\n",
              "9998       9999    15682355  Sabbatini  ...               0        92888.52      1\n",
              "9999      10000    15628319     Walker  ...               0        38190.78      0\n",
              "\n",
              "[10000 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVqnBFu6hN2c"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RtuEDIKrI5I",
        "outputId": "348328ba-1e30-4a96-bf00-6f199ff53675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPUrEV8NhCJA",
        "outputId": "ea9dc0f6-3768-42d0-9577-017975b214b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['RowNumber', 'CustomerId', 'Surname', 'CreditScore', 'Geography',\n",
              "       'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard',\n",
              "       'IsActiveMember', 'EstimatedSalary', 'Exited'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RYxY1cRmtVx",
        "outputId": "1b1efecc-4997-4afb-a675-a5a9078c8c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RowNumber          0\n",
              "CustomerId         0\n",
              "Surname            0\n",
              "CreditScore        0\n",
              "Geography          0\n",
              "Gender             0\n",
              "Age                0\n",
              "Tenure             0\n",
              "Balance            0\n",
              "NumOfProducts      0\n",
              "HasCrCard          0\n",
              "IsActiveMember     0\n",
              "EstimatedSalary    0\n",
              "Exited             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzX2O-RUhgbV",
        "outputId": "2d20d742-e65b-4d32-fabf-b120fc48b27a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RowNumber          10000\n",
              "CustomerId         10000\n",
              "Surname             2932\n",
              "CreditScore          460\n",
              "Geography              3\n",
              "Gender                 2\n",
              "Age                   70\n",
              "Tenure                11\n",
              "Balance             6382\n",
              "NumOfProducts          4\n",
              "HasCrCard              2\n",
              "IsActiveMember         2\n",
              "EstimatedSalary     9999\n",
              "Exited                 2\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OMJbk2ChgrZ",
        "outputId": "755ac7ae-935b-478b-8521-115a1e8bfac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RowNumber            int64\n",
              "CustomerId           int64\n",
              "Surname             object\n",
              "CreditScore          int64\n",
              "Geography           object\n",
              "Gender              object\n",
              "Age                  int64\n",
              "Tenure               int64\n",
              "Balance            float64\n",
              "NumOfProducts        int64\n",
              "HasCrCard            int64\n",
              "IsActiveMember       int64\n",
              "EstimatedSalary    float64\n",
              "Exited               int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QI5yOMthggM",
        "outputId": "230d2f28-e28c-4494-b41f-f34c615bf0d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.heatmap(df.isnull())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcce0192ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wBWJJsUq1sU",
        "outputId": "5791d5da-fcbd-42dd-a9b5-0ab4821737aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "sns.countplot('Exited', data=df)\n",
        "plt.show()\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ci_pLMNrtMi"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder=LabelEncoder()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tNhSLVKrtJT",
        "outputId": "3528e52f-fc9e-4990-f3e8-23939121b9a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df1=df.select_dtypes(include='object')\n",
        "df1.columns"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Surname', 'Geography', 'Gender'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDNDGrsfoqjI"
      },
      "source": [
        "cols=['Surname', 'Geography', 'Gender']\n",
        "for i in cols:\n",
        "  df[i]=encoder.fit_transform(df[i])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB3Ery-b4UZw",
        "outputId": "e4817d99-2a50-49f5-c46a-e5cee153e74b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>1115</td>\n",
              "      <td>619</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>1177</td>\n",
              "      <td>608</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>2040</td>\n",
              "      <td>502</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>289</td>\n",
              "      <td>699</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>1822</td>\n",
              "      <td>850</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>9996</td>\n",
              "      <td>15606229</td>\n",
              "      <td>1999</td>\n",
              "      <td>771</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>96270.64</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>9997</td>\n",
              "      <td>15569892</td>\n",
              "      <td>1336</td>\n",
              "      <td>516</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>10</td>\n",
              "      <td>57369.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101699.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>9998</td>\n",
              "      <td>15584532</td>\n",
              "      <td>1570</td>\n",
              "      <td>709</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>42085.58</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>9999</td>\n",
              "      <td>15682355</td>\n",
              "      <td>2345</td>\n",
              "      <td>772</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>42</td>\n",
              "      <td>3</td>\n",
              "      <td>75075.31</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>92888.52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>10000</td>\n",
              "      <td>15628319</td>\n",
              "      <td>2751</td>\n",
              "      <td>792</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>130142.79</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>38190.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      RowNumber  CustomerId  Surname  ...  IsActiveMember  EstimatedSalary  Exited\n",
              "0             1    15634602     1115  ...               1        101348.88       1\n",
              "1             2    15647311     1177  ...               1        112542.58       0\n",
              "2             3    15619304     2040  ...               0        113931.57       1\n",
              "3             4    15701354      289  ...               0         93826.63       0\n",
              "4             5    15737888     1822  ...               1         79084.10       0\n",
              "...         ...         ...      ...  ...             ...              ...     ...\n",
              "9995       9996    15606229     1999  ...               0         96270.64       0\n",
              "9996       9997    15569892     1336  ...               1        101699.77       0\n",
              "9997       9998    15584532     1570  ...               1         42085.58       1\n",
              "9998       9999    15682355     2345  ...               0         92888.52       1\n",
              "9999      10000    15628319     2751  ...               0         38190.78       0\n",
              "\n",
              "[10000 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCM1iVxI4U3E",
        "outputId": "51fa3a8e-10e5-4170-8bc5-c498d9ec9d8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RowNumber            int64\n",
              "CustomerId           int64\n",
              "Surname              int64\n",
              "CreditScore          int64\n",
              "Geography            int64\n",
              "Gender               int64\n",
              "Age                  int64\n",
              "Tenure               int64\n",
              "Balance            float64\n",
              "NumOfProducts        int64\n",
              "HasCrCard            int64\n",
              "IsActiveMember       int64\n",
              "EstimatedSalary    float64\n",
              "Exited               int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l3O1D2I5xSb"
      },
      "source": [
        "X = df.iloc[:,3:13]\n",
        "y = df.iloc[:,13]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=10)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jftbg2kV5xOt",
        "outputId": "6fceaba0-2024-44b5-8a8d-6d4806466cfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrYVvTAd9FUY",
        "outputId": "b9eadc66-7a2c-4943-a1ec-eb3c50651185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV9vnRf15xLu",
        "outputId": "6a3c7294-ea9e-4ba4-82aa-acce1e143cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(X_train.columns)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLUq_l9u5xHC"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "s = StandardScaler()\n",
        "X_train = s.fit_transform(X_train)\n",
        "X_test = s.transform(X_test)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur5_241-5xBu"
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX8_sOyZq5W8",
        "outputId": "0381ad92-349a-44b4-e583-cf1c366cfbfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def create_model(dense_layers,activation,optimizer):\n",
        "    model = Sequential()\n",
        "    for index, lsize in enumerate(dense_layers):\n",
        "        # Input Layer - includes the input_shape\n",
        "        if index == 0:\n",
        "          model.add(Dense(lsize,activation=activation,input_shape=(10,)))\n",
        "        else:\n",
        "          model.add(Dense(lsize,activation=activation))   \n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    model.compile(optimizer = optimizer,loss='binary_crossentropy',metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model,verbose=1)\n",
        "\n",
        "param_grid = {'dense_layers': [(8),(8,4)],\n",
        "              'activation':['relu'],\n",
        "              'optimizer':['adam'],\n",
        "              'epochs':[50],\n",
        "              'batch_size':[64]}\n",
        "\n",
        "grid = GridSearchCV(model,param_grid=param_grid, cv=5)\n",
        "\n",
        "grid_results = grid.fit(X_train,y_train)\n",
        "\n",
        "print('Parameters of the best model: ')\n",
        "print(grid_results.best_params_)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: 'int' object is not iterable\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.7395\n",
            "Epoch 2/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7986\n",
            "Epoch 3/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7986\n",
            "Epoch 4/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4489 - accuracy: 0.7986\n",
            "Epoch 5/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4390 - accuracy: 0.7986\n",
            "Epoch 6/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.7986\n",
            "Epoch 7/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7986\n",
            "Epoch 8/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4234 - accuracy: 0.7989\n",
            "Epoch 9/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.8032\n",
            "Epoch 10/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8055\n",
            "Epoch 11/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4131 - accuracy: 0.8071\n",
            "Epoch 12/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8104\n",
            "Epoch 13/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4066 - accuracy: 0.8138\n",
            "Epoch 14/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.8186\n",
            "Epoch 15/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4005 - accuracy: 0.8227\n",
            "Epoch 16/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3977 - accuracy: 0.8238\n",
            "Epoch 17/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3950 - accuracy: 0.8243\n",
            "Epoch 18/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3922 - accuracy: 0.8261\n",
            "Epoch 19/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8259\n",
            "Epoch 20/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3877 - accuracy: 0.8261\n",
            "Epoch 21/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3856 - accuracy: 0.8273\n",
            "Epoch 22/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3840 - accuracy: 0.8288\n",
            "Epoch 23/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3821 - accuracy: 0.8293\n",
            "Epoch 24/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3803 - accuracy: 0.8307\n",
            "Epoch 25/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3790 - accuracy: 0.8341\n",
            "Epoch 26/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3774 - accuracy: 0.8350\n",
            "Epoch 27/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3758 - accuracy: 0.8354\n",
            "Epoch 28/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8366\n",
            "Epoch 29/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3738 - accuracy: 0.8375\n",
            "Epoch 30/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8395\n",
            "Epoch 31/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8409\n",
            "Epoch 32/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8393\n",
            "Epoch 33/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8418\n",
            "Epoch 34/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8434\n",
            "Epoch 35/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.8438\n",
            "Epoch 36/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8443\n",
            "Epoch 37/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8455\n",
            "Epoch 38/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8475\n",
            "Epoch 39/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8505\n",
            "Epoch 40/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3613 - accuracy: 0.8507\n",
            "Epoch 41/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8516\n",
            "Epoch 42/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8512\n",
            "Epoch 43/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8514\n",
            "Epoch 44/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3573 - accuracy: 0.8507\n",
            "Epoch 45/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3564 - accuracy: 0.8525\n",
            "Epoch 46/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8521\n",
            "Epoch 47/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8530\n",
            "Epoch 48/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3541 - accuracy: 0.8539\n",
            "Epoch 49/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8536\n",
            "Epoch 50/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8570\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8493\n",
            "Epoch 1/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.5714 - accuracy: 0.7970\n",
            "Epoch 2/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.8007\n",
            "Epoch 3/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8007\n",
            "Epoch 4/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.8007\n",
            "Epoch 5/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4515 - accuracy: 0.8007\n",
            "Epoch 6/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.8007\n",
            "Epoch 7/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.8007\n",
            "Epoch 8/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4337 - accuracy: 0.8007\n",
            "Epoch 9/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8007\n",
            "Epoch 10/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8007\n",
            "Epoch 11/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8011\n",
            "Epoch 12/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8064\n",
            "Epoch 13/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4231 - accuracy: 0.8071\n",
            "Epoch 14/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8129\n",
            "Epoch 15/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8148\n",
            "Epoch 16/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8173\n",
            "Epoch 17/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8182\n",
            "Epoch 18/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8198\n",
            "Epoch 19/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4122 - accuracy: 0.8213\n",
            "Epoch 20/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4099 - accuracy: 0.8230\n",
            "Epoch 21/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8264\n",
            "Epoch 22/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4054 - accuracy: 0.8261\n",
            "Epoch 23/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4031 - accuracy: 0.8275\n",
            "Epoch 24/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8286\n",
            "Epoch 25/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8298\n",
            "Epoch 26/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3965 - accuracy: 0.8296\n",
            "Epoch 27/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8316\n",
            "Epoch 28/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3923 - accuracy: 0.8316\n",
            "Epoch 29/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8309\n",
            "Epoch 30/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8336\n",
            "Epoch 31/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3864 - accuracy: 0.8330\n",
            "Epoch 32/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3848 - accuracy: 0.8357\n",
            "Epoch 33/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3836 - accuracy: 0.8346\n",
            "Epoch 34/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3816 - accuracy: 0.8373\n",
            "Epoch 35/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3800 - accuracy: 0.8382\n",
            "Epoch 36/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.8389\n",
            "Epoch 37/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8375\n",
            "Epoch 38/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3766 - accuracy: 0.8402\n",
            "Epoch 39/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8411\n",
            "Epoch 40/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3739 - accuracy: 0.8409\n",
            "Epoch 41/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3729 - accuracy: 0.8421\n",
            "Epoch 42/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3717 - accuracy: 0.8434\n",
            "Epoch 43/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8439\n",
            "Epoch 44/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8446\n",
            "Epoch 45/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8468\n",
            "Epoch 46/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3679 - accuracy: 0.8448\n",
            "Epoch 47/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3669 - accuracy: 0.8455\n",
            "Epoch 48/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8480\n",
            "Epoch 49/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8484\n",
            "Epoch 50/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8468\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3707 - accuracy: 0.8421\n",
            "Epoch 1/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.7821\n",
            "Epoch 2/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7946\n",
            "Epoch 3/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7945\n",
            "Epoch 4/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7957\n",
            "Epoch 5/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4452 - accuracy: 0.7989\n",
            "Epoch 6/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4384 - accuracy: 0.8021\n",
            "Epoch 7/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.8023\n",
            "Epoch 8/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8068\n",
            "Epoch 9/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4239 - accuracy: 0.8114\n",
            "Epoch 10/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8148\n",
            "Epoch 11/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8164\n",
            "Epoch 12/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4133 - accuracy: 0.8204\n",
            "Epoch 13/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8246\n",
            "Epoch 14/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4053 - accuracy: 0.8282\n",
            "Epoch 15/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8341\n",
            "Epoch 16/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3947 - accuracy: 0.8395\n",
            "Epoch 17/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3887 - accuracy: 0.8459\n",
            "Epoch 18/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8495\n",
            "Epoch 19/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3772 - accuracy: 0.8525\n",
            "Epoch 20/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8546\n",
            "Epoch 21/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3675 - accuracy: 0.8562\n",
            "Epoch 22/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8584\n",
            "Epoch 23/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8579\n",
            "Epoch 24/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8602\n",
            "Epoch 25/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3547 - accuracy: 0.8618\n",
            "Epoch 26/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8614\n",
            "Epoch 27/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8616\n",
            "Epoch 28/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8625\n",
            "Epoch 29/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8623\n",
            "Epoch 30/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8630\n",
            "Epoch 31/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8637\n",
            "Epoch 32/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3452 - accuracy: 0.8623\n",
            "Epoch 33/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8629\n",
            "Epoch 34/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3440 - accuracy: 0.8636\n",
            "Epoch 35/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3432 - accuracy: 0.8637\n",
            "Epoch 36/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8636\n",
            "Epoch 37/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8630\n",
            "Epoch 38/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3420 - accuracy: 0.8632\n",
            "Epoch 39/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8634\n",
            "Epoch 40/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8643\n",
            "Epoch 41/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8621\n",
            "Epoch 42/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8627\n",
            "Epoch 43/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.8637\n",
            "Epoch 44/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8634\n",
            "Epoch 45/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8630\n",
            "Epoch 46/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8627\n",
            "Epoch 47/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3394 - accuracy: 0.8629\n",
            "Epoch 48/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8630\n",
            "Epoch 49/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8636\n",
            "Epoch 50/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8637\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3601 - accuracy: 0.8471\n",
            "Epoch 1/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.6394 - accuracy: 0.6830\n",
            "Epoch 2/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7991\n",
            "Epoch 4/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.7991\n",
            "Epoch 5/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7991\n",
            "Epoch 6/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4436 - accuracy: 0.7991\n",
            "Epoch 7/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4378 - accuracy: 0.7991\n",
            "Epoch 8/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.7991\n",
            "Epoch 9/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7991\n",
            "Epoch 10/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7991\n",
            "Epoch 11/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4248 - accuracy: 0.7991\n",
            "Epoch 12/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4225 - accuracy: 0.7991\n",
            "Epoch 13/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4199 - accuracy: 0.7991\n",
            "Epoch 14/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4173 - accuracy: 0.7991\n",
            "Epoch 15/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7991\n",
            "Epoch 16/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4121 - accuracy: 0.7991\n",
            "Epoch 17/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.7991\n",
            "Epoch 18/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.7991\n",
            "Epoch 19/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4038 - accuracy: 0.7998\n",
            "Epoch 20/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4006 - accuracy: 0.8037\n",
            "Epoch 21/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3974 - accuracy: 0.8164\n",
            "Epoch 22/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3935 - accuracy: 0.8313\n",
            "Epoch 23/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8330\n",
            "Epoch 24/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3868 - accuracy: 0.8371\n",
            "Epoch 25/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8398\n",
            "Epoch 26/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3802 - accuracy: 0.8425\n",
            "Epoch 27/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8445\n",
            "Epoch 28/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8454\n",
            "Epoch 29/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3723 - accuracy: 0.8495\n",
            "Epoch 30/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3701 - accuracy: 0.8521\n",
            "Epoch 31/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3683 - accuracy: 0.8518\n",
            "Epoch 32/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3666 - accuracy: 0.8525\n",
            "Epoch 33/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8539\n",
            "Epoch 34/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3635 - accuracy: 0.8543\n",
            "Epoch 35/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3622 - accuracy: 0.8552\n",
            "Epoch 36/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3606 - accuracy: 0.8562\n",
            "Epoch 37/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.8566\n",
            "Epoch 38/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3584 - accuracy: 0.8571\n",
            "Epoch 39/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8591\n",
            "Epoch 40/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8587\n",
            "Epoch 41/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3544 - accuracy: 0.8595\n",
            "Epoch 42/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8605\n",
            "Epoch 43/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3525 - accuracy: 0.8609\n",
            "Epoch 44/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.8618\n",
            "Epoch 45/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8616\n",
            "Epoch 46/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3500 - accuracy: 0.8630\n",
            "Epoch 47/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8621\n",
            "Epoch 48/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8641\n",
            "Epoch 49/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8643\n",
            "Epoch 50/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3479 - accuracy: 0.8645\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8471\n",
            "Epoch 1/50\n",
            "88/88 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.7950\n",
            "Epoch 2/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7950\n",
            "Epoch 3/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7950\n",
            "Epoch 4/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7950\n",
            "Epoch 5/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4514 - accuracy: 0.7950\n",
            "Epoch 6/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.7950\n",
            "Epoch 7/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4387 - accuracy: 0.7950\n",
            "Epoch 8/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.7950\n",
            "Epoch 9/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7950\n",
            "Epoch 10/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7950\n",
            "Epoch 11/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.7950\n",
            "Epoch 12/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4211 - accuracy: 0.7950\n",
            "Epoch 13/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4180 - accuracy: 0.7950\n",
            "Epoch 14/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.7950\n",
            "Epoch 15/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8002\n",
            "Epoch 16/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8168\n",
            "Epoch 17/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8246\n",
            "Epoch 18/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3995 - accuracy: 0.8304\n",
            "Epoch 19/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8355\n",
            "Epoch 20/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3925 - accuracy: 0.8364\n",
            "Epoch 21/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8407\n",
            "Epoch 22/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8420\n",
            "Epoch 23/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3832 - accuracy: 0.8430\n",
            "Epoch 24/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3804 - accuracy: 0.8445\n",
            "Epoch 25/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8471\n",
            "Epoch 26/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8487\n",
            "Epoch 27/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8502\n",
            "Epoch 28/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8514\n",
            "Epoch 29/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8532\n",
            "Epoch 30/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3680 - accuracy: 0.8552\n",
            "Epoch 31/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3661 - accuracy: 0.8557\n",
            "Epoch 32/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8555\n",
            "Epoch 33/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3632 - accuracy: 0.8573\n",
            "Epoch 34/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8586\n",
            "Epoch 35/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3605 - accuracy: 0.8591\n",
            "Epoch 36/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3589 - accuracy: 0.8589\n",
            "Epoch 37/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8589\n",
            "Epoch 38/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8587\n",
            "Epoch 39/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3552 - accuracy: 0.8573\n",
            "Epoch 40/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8605\n",
            "Epoch 41/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3528 - accuracy: 0.8596\n",
            "Epoch 42/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3520 - accuracy: 0.8605\n",
            "Epoch 43/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3507 - accuracy: 0.8612\n",
            "Epoch 44/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3501 - accuracy: 0.8595\n",
            "Epoch 45/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8612\n",
            "Epoch 46/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8602\n",
            "Epoch 47/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3472 - accuracy: 0.8618\n",
            "Epoch 48/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3464 - accuracy: 0.8607\n",
            "Epoch 49/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3456 - accuracy: 0.8607\n",
            "Epoch 50/50\n",
            "88/88 [==============================] - 0s 2ms/step - loss: 0.3448 - accuracy: 0.8602\n",
            "22/22 [==============================] - 0s 2ms/step - loss: 0.3510 - accuracy: 0.8564\n",
            "Epoch 1/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.7006\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.7946\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7976\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7976\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7977\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4469 - accuracy: 0.8000\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.8063\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8107\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8150\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8186\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8204\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8214\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4156 - accuracy: 0.8240\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4123 - accuracy: 0.8249\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4093 - accuracy: 0.8240\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4065 - accuracy: 0.8269\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8289\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.4009 - accuracy: 0.8290\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8280\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3961 - accuracy: 0.8291\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3937 - accuracy: 0.8296\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3914 - accuracy: 0.8311\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8300\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3866 - accuracy: 0.8311\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3844 - accuracy: 0.8299\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3822 - accuracy: 0.8323\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3801 - accuracy: 0.8319\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3778 - accuracy: 0.8331\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3755 - accuracy: 0.8320\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8329\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8379\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8397\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3673 - accuracy: 0.8443\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8463\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3634 - accuracy: 0.8466\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3611 - accuracy: 0.8481\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8511\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8521\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3535 - accuracy: 0.8564\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8551\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8559\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 0.3485 - accuracy: 0.8577\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8571\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.8591\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8586\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3437 - accuracy: 0.8597\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3430 - accuracy: 0.8583\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.8587\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8587\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8584\n",
            "Parameters of the best model: \n",
            "{'activation': 'relu', 'batch_size': 64, 'dense_layers': (8, 4), 'epochs': 50, 'optimizer': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKzEFDIvWUTR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d75JhWMbspiL",
        "outputId": "a0002f99-712a-4f97-dce1-50d84b4ee6ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "params=grid_results.best_params_\n",
        "params"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 64,\n",
              " 'dense_layers': (8, 4),\n",
              " 'epochs': 50,\n",
              " 'optimizer': 'adam'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBKeRtnisrPc",
        "outputId": "f0ef293e-42c4-4d49-ce85-6a766961d0a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(8, input_dim=10, activation='relu'),\n",
        "    Dense(4, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "r=model.fit(X_train, y_train, epochs=50, batch_size=64,validation_data=(X_test,y_test))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 0.7671 - accuracy: 0.4017 - val_loss: 0.6653 - val_accuracy: 0.6193\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.7403 - val_loss: 0.5301 - val_accuracy: 0.7930\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.8066 - val_loss: 0.4713 - val_accuracy: 0.7943\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.8149 - val_loss: 0.4502 - val_accuracy: 0.8040\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8209 - val_loss: 0.4391 - val_accuracy: 0.8090\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4219 - accuracy: 0.8271 - val_loss: 0.4302 - val_accuracy: 0.8120\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8326 - val_loss: 0.4215 - val_accuracy: 0.8147\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8383 - val_loss: 0.4136 - val_accuracy: 0.8210\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3946 - accuracy: 0.8433 - val_loss: 0.4060 - val_accuracy: 0.8270\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8479 - val_loss: 0.3982 - val_accuracy: 0.8323\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8509 - val_loss: 0.3924 - val_accuracy: 0.8390\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8531 - val_loss: 0.3870 - val_accuracy: 0.8423\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3656 - accuracy: 0.8566 - val_loss: 0.3830 - val_accuracy: 0.8427\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3613 - accuracy: 0.8566 - val_loss: 0.3808 - val_accuracy: 0.8433\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3582 - accuracy: 0.8581 - val_loss: 0.3786 - val_accuracy: 0.8430\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3556 - accuracy: 0.8577 - val_loss: 0.3773 - val_accuracy: 0.8443\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3536 - accuracy: 0.8580 - val_loss: 0.3760 - val_accuracy: 0.8440\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8589 - val_loss: 0.3747 - val_accuracy: 0.8427\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8584 - val_loss: 0.3738 - val_accuracy: 0.8427\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8576 - val_loss: 0.3737 - val_accuracy: 0.8420\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8591 - val_loss: 0.3733 - val_accuracy: 0.8467\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3473 - accuracy: 0.8594 - val_loss: 0.3722 - val_accuracy: 0.8447\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8590 - val_loss: 0.3722 - val_accuracy: 0.8467\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3462 - accuracy: 0.8583 - val_loss: 0.3714 - val_accuracy: 0.8477\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8587 - val_loss: 0.3712 - val_accuracy: 0.8477\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8591 - val_loss: 0.3709 - val_accuracy: 0.8487\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3441 - accuracy: 0.8600 - val_loss: 0.3708 - val_accuracy: 0.8500\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8586 - val_loss: 0.3693 - val_accuracy: 0.8480\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3424 - accuracy: 0.8599 - val_loss: 0.3688 - val_accuracy: 0.8470\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8603 - val_loss: 0.3688 - val_accuracy: 0.8493\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8590 - val_loss: 0.3677 - val_accuracy: 0.8490\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.8600 - val_loss: 0.3674 - val_accuracy: 0.8480\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8603 - val_loss: 0.3681 - val_accuracy: 0.8510\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8599 - val_loss: 0.3671 - val_accuracy: 0.8513\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8611 - val_loss: 0.3664 - val_accuracy: 0.8487\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.8611 - val_loss: 0.3662 - val_accuracy: 0.8520\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.8619 - val_loss: 0.3659 - val_accuracy: 0.8487\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8607 - val_loss: 0.3658 - val_accuracy: 0.8500\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8610 - val_loss: 0.3652 - val_accuracy: 0.8497\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8609 - val_loss: 0.3650 - val_accuracy: 0.8490\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8617 - val_loss: 0.3650 - val_accuracy: 0.8490\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8609 - val_loss: 0.3649 - val_accuracy: 0.8520\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8626 - val_loss: 0.3651 - val_accuracy: 0.8497\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3354 - accuracy: 0.8616 - val_loss: 0.3648 - val_accuracy: 0.8510\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8619 - val_loss: 0.3643 - val_accuracy: 0.8517\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8610 - val_loss: 0.3644 - val_accuracy: 0.8513\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.8614 - val_loss: 0.3649 - val_accuracy: 0.8513\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8614 - val_loss: 0.3644 - val_accuracy: 0.8523\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8644 - val_loss: 0.3640 - val_accuracy: 0.8517\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.3327 - accuracy: 0.8631 - val_loss: 0.3638 - val_accuracy: 0.8533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF1cM7Jtsrv7",
        "outputId": "7f0ef4ec-8ee6-4572-aa7a-cef158bd93b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "yp= model.predict(X_test)\n",
        "yp"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6358395 ],\n",
              "       [0.57408905],\n",
              "       [0.6702301 ],\n",
              "       ...,\n",
              "       [0.3855124 ],\n",
              "       [0.09114679],\n",
              "       [0.03823144]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTDZsEantaZC"
      },
      "source": [
        "\n",
        "y_pred = []\n",
        "for element in yp:\n",
        "    if element > 0.5:\n",
        "        y_pred.append(1)\n",
        "    else:\n",
        "        y_pred.append(0)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IVgoB9X4tZD",
        "outputId": "a7096aab-2636-4962-d32d-30ab806966f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_pred"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6iDuHM_4teP",
        "outputId": "39793d34-8a9d-4c11-fa98-e16f29eae2b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_labels=np.unique(y_pred, return_counts=True)\n",
        "y_pred_labels"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([2660,  340]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYOvTPHG4tVj",
        "outputId": "f87b3a47-b304-4bd8-d40c-679edc379119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "y_test_labels=np.unique(y_test, return_counts=True)\n",
        "y_test_labels"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([2380,  620]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7LCIQk-43-v",
        "outputId": "9b9e27f7-133b-458d-9dc3-320c1eccff8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c_m = confusion_matrix(y_test, y_pred)\n",
        "c_m\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2300,   80],\n",
              "       [ 360,  260]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92K4KKMf44G6",
        "outputId": "87cfd3fa-734f-47ca-b515-c03894567a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize = (6,6))\n",
        "sns.heatmap(c_m,cmap= \"Reds\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' )"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcc747719e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R66qfdUb44qy",
        "outputId": "4a4bb064-4e76-49b8-b24d-d372587532fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.97      0.91      2380\n",
            "           1       0.76      0.42      0.54       620\n",
            "\n",
            "    accuracy                           0.85      3000\n",
            "   macro avg       0.81      0.69      0.73      3000\n",
            "weighted avg       0.84      0.85      0.84      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo5-m4-FM1yB",
        "outputId": "f85dab3c-fbd7-4473-ebcd-4fd8c47fe50d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L32qM9YZO5kc",
        "outputId": "36414732-537a-4f63-90a2-6bc9bae485f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "os=SMOTETomek()\n",
        "X_train_ns,y_train_ns=os.fit_sample(X_train,y_train)\n",
        "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
        "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The number of classes before fit Counter({0: 5583, 1: 1417})\n",
            "The number of classes after fit Counter({0: 5524, 1: 5524})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1s4gYBEPCfP",
        "outputId": "eecaa68c-7ea6-441c-a1a2-312bd9ddd6b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model1 = Sequential([\n",
        "    Dense(8, input_dim=10, activation='relu'),\n",
        "    Dense(4, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "rs=model1.fit(X_train_ns, y_train_ns, epochs=500, batch_size=64,validation_data=(X_test,y_test))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.7114 - accuracy: 0.5217 - val_loss: 0.6868 - val_accuracy: 0.6027\n",
            "Epoch 2/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.6330 - accuracy: 0.6407 - val_loss: 0.6036 - val_accuracy: 0.6730\n",
            "Epoch 3/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.6989 - val_loss: 0.5897 - val_accuracy: 0.6730\n",
            "Epoch 4/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7182 - val_loss: 0.5745 - val_accuracy: 0.6833\n",
            "Epoch 5/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7293 - val_loss: 0.5656 - val_accuracy: 0.6763\n",
            "Epoch 6/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7461 - val_loss: 0.5641 - val_accuracy: 0.6793\n",
            "Epoch 7/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7504 - val_loss: 0.5430 - val_accuracy: 0.6973\n",
            "Epoch 8/500\n",
            "173/173 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.7577 - val_loss: 0.5349 - val_accuracy: 0.7010\n",
            "Epoch 9/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7625 - val_loss: 0.5068 - val_accuracy: 0.7263\n",
            "Epoch 10/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7687 - val_loss: 0.5048 - val_accuracy: 0.7280\n",
            "Epoch 11/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7718 - val_loss: 0.5134 - val_accuracy: 0.7247\n",
            "Epoch 12/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7798 - val_loss: 0.4923 - val_accuracy: 0.7413\n",
            "Epoch 13/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4454 - accuracy: 0.7837 - val_loss: 0.4863 - val_accuracy: 0.7447\n",
            "Epoch 14/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7857 - val_loss: 0.5067 - val_accuracy: 0.7323\n",
            "Epoch 15/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7884 - val_loss: 0.4969 - val_accuracy: 0.7437\n",
            "Epoch 16/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7892 - val_loss: 0.4797 - val_accuracy: 0.7553\n",
            "Epoch 17/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4378 - accuracy: 0.7901 - val_loss: 0.4908 - val_accuracy: 0.7493\n",
            "Epoch 18/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.7894 - val_loss: 0.4838 - val_accuracy: 0.7553\n",
            "Epoch 19/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7936 - val_loss: 0.4893 - val_accuracy: 0.7543\n",
            "Epoch 20/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4335 - accuracy: 0.7935 - val_loss: 0.4881 - val_accuracy: 0.7570\n",
            "Epoch 21/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7964 - val_loss: 0.4816 - val_accuracy: 0.7597\n",
            "Epoch 22/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7947 - val_loss: 0.4842 - val_accuracy: 0.7590\n",
            "Epoch 23/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7957 - val_loss: 0.4838 - val_accuracy: 0.7583\n",
            "Epoch 24/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7972 - val_loss: 0.4771 - val_accuracy: 0.7643\n",
            "Epoch 25/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7963 - val_loss: 0.4938 - val_accuracy: 0.7567\n",
            "Epoch 26/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7980 - val_loss: 0.4916 - val_accuracy: 0.7577\n",
            "Epoch 27/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7976 - val_loss: 0.4916 - val_accuracy: 0.7557\n",
            "Epoch 28/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7982 - val_loss: 0.4813 - val_accuracy: 0.7637\n",
            "Epoch 29/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7982 - val_loss: 0.4725 - val_accuracy: 0.7710\n",
            "Epoch 30/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.7991 - val_loss: 0.4910 - val_accuracy: 0.7570\n",
            "Epoch 31/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7992 - val_loss: 0.4654 - val_accuracy: 0.7770\n",
            "Epoch 32/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8001 - val_loss: 0.4822 - val_accuracy: 0.7657\n",
            "Epoch 33/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.7997 - val_loss: 0.4754 - val_accuracy: 0.7717\n",
            "Epoch 34/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7989 - val_loss: 0.4851 - val_accuracy: 0.7657\n",
            "Epoch 35/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8002 - val_loss: 0.4827 - val_accuracy: 0.7663\n",
            "Epoch 36/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8001 - val_loss: 0.4744 - val_accuracy: 0.7740\n",
            "Epoch 37/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4218 - accuracy: 0.7991 - val_loss: 0.4916 - val_accuracy: 0.7613\n",
            "Epoch 38/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.7971 - val_loss: 0.4822 - val_accuracy: 0.7673\n",
            "Epoch 39/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4216 - accuracy: 0.7999 - val_loss: 0.4801 - val_accuracy: 0.7693\n",
            "Epoch 40/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.7985 - val_loss: 0.4810 - val_accuracy: 0.7683\n",
            "Epoch 41/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8007 - val_loss: 0.4924 - val_accuracy: 0.7613\n",
            "Epoch 42/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7977 - val_loss: 0.4868 - val_accuracy: 0.7630\n",
            "Epoch 43/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4204 - accuracy: 0.7997 - val_loss: 0.4933 - val_accuracy: 0.7617\n",
            "Epoch 44/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.7978 - val_loss: 0.4892 - val_accuracy: 0.7617\n",
            "Epoch 45/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7999 - val_loss: 0.4862 - val_accuracy: 0.7650\n",
            "Epoch 46/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.7997 - val_loss: 0.4901 - val_accuracy: 0.7620\n",
            "Epoch 47/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8004 - val_loss: 0.4745 - val_accuracy: 0.7740\n",
            "Epoch 48/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.8010 - val_loss: 0.4703 - val_accuracy: 0.7750\n",
            "Epoch 49/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8018 - val_loss: 0.4772 - val_accuracy: 0.7740\n",
            "Epoch 50/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8009 - val_loss: 0.4708 - val_accuracy: 0.7767\n",
            "Epoch 51/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8015 - val_loss: 0.4829 - val_accuracy: 0.7667\n",
            "Epoch 52/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8005 - val_loss: 0.4951 - val_accuracy: 0.7607\n",
            "Epoch 53/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8013 - val_loss: 0.4718 - val_accuracy: 0.7747\n",
            "Epoch 54/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8002 - val_loss: 0.4804 - val_accuracy: 0.7670\n",
            "Epoch 55/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8018 - val_loss: 0.4814 - val_accuracy: 0.7700\n",
            "Epoch 56/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.8022 - val_loss: 0.4643 - val_accuracy: 0.7797\n",
            "Epoch 57/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8025 - val_loss: 0.4542 - val_accuracy: 0.7870\n",
            "Epoch 58/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8010 - val_loss: 0.4624 - val_accuracy: 0.7810\n",
            "Epoch 59/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8038 - val_loss: 0.4590 - val_accuracy: 0.7857\n",
            "Epoch 60/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8024 - val_loss: 0.4757 - val_accuracy: 0.7747\n",
            "Epoch 61/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8011 - val_loss: 0.4805 - val_accuracy: 0.7700\n",
            "Epoch 62/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8030 - val_loss: 0.4645 - val_accuracy: 0.7823\n",
            "Epoch 63/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8041 - val_loss: 0.4751 - val_accuracy: 0.7750\n",
            "Epoch 64/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8018 - val_loss: 0.4885 - val_accuracy: 0.7690\n",
            "Epoch 65/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8031 - val_loss: 0.4671 - val_accuracy: 0.7783\n",
            "Epoch 66/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8023 - val_loss: 0.4721 - val_accuracy: 0.7763\n",
            "Epoch 67/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8034 - val_loss: 0.4638 - val_accuracy: 0.7830\n",
            "Epoch 68/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8037 - val_loss: 0.4785 - val_accuracy: 0.7717\n",
            "Epoch 69/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8024 - val_loss: 0.4832 - val_accuracy: 0.7693\n",
            "Epoch 70/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8060 - val_loss: 0.4606 - val_accuracy: 0.7877\n",
            "Epoch 71/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8029 - val_loss: 0.4823 - val_accuracy: 0.7707\n",
            "Epoch 72/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8058 - val_loss: 0.4722 - val_accuracy: 0.7757\n",
            "Epoch 73/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8049 - val_loss: 0.4774 - val_accuracy: 0.7737\n",
            "Epoch 74/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8019 - val_loss: 0.4703 - val_accuracy: 0.7797\n",
            "Epoch 75/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8041 - val_loss: 0.4619 - val_accuracy: 0.7847\n",
            "Epoch 76/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4142 - accuracy: 0.8055 - val_loss: 0.4872 - val_accuracy: 0.7687\n",
            "Epoch 77/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8053 - val_loss: 0.4648 - val_accuracy: 0.7830\n",
            "Epoch 78/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8068 - val_loss: 0.4699 - val_accuracy: 0.7800\n",
            "Epoch 79/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8044 - val_loss: 0.4674 - val_accuracy: 0.7807\n",
            "Epoch 80/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8059 - val_loss: 0.4748 - val_accuracy: 0.7763\n",
            "Epoch 81/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4133 - accuracy: 0.8039 - val_loss: 0.4705 - val_accuracy: 0.7763\n",
            "Epoch 82/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8065 - val_loss: 0.4463 - val_accuracy: 0.7947\n",
            "Epoch 83/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8051 - val_loss: 0.4613 - val_accuracy: 0.7857\n",
            "Epoch 84/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8060 - val_loss: 0.4714 - val_accuracy: 0.7797\n",
            "Epoch 85/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8029 - val_loss: 0.4741 - val_accuracy: 0.7757\n",
            "Epoch 86/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8082 - val_loss: 0.4634 - val_accuracy: 0.7817\n",
            "Epoch 87/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8064 - val_loss: 0.4698 - val_accuracy: 0.7793\n",
            "Epoch 88/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8049 - val_loss: 0.4850 - val_accuracy: 0.7707\n",
            "Epoch 89/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8063 - val_loss: 0.4732 - val_accuracy: 0.7777\n",
            "Epoch 90/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8043 - val_loss: 0.4803 - val_accuracy: 0.7720\n",
            "Epoch 91/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8073 - val_loss: 0.4548 - val_accuracy: 0.7873\n",
            "Epoch 92/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8056 - val_loss: 0.4728 - val_accuracy: 0.7790\n",
            "Epoch 93/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8058 - val_loss: 0.4746 - val_accuracy: 0.7743\n",
            "Epoch 94/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4112 - accuracy: 0.8057 - val_loss: 0.4583 - val_accuracy: 0.7890\n",
            "Epoch 95/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8071 - val_loss: 0.4779 - val_accuracy: 0.7767\n",
            "Epoch 96/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8083 - val_loss: 0.4845 - val_accuracy: 0.7707\n",
            "Epoch 97/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8069 - val_loss: 0.4631 - val_accuracy: 0.7840\n",
            "Epoch 98/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8068 - val_loss: 0.4510 - val_accuracy: 0.7913\n",
            "Epoch 99/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8077 - val_loss: 0.4580 - val_accuracy: 0.7863\n",
            "Epoch 100/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8062 - val_loss: 0.4659 - val_accuracy: 0.7830\n",
            "Epoch 101/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8077 - val_loss: 0.4553 - val_accuracy: 0.7907\n",
            "Epoch 102/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8072 - val_loss: 0.4599 - val_accuracy: 0.7850\n",
            "Epoch 103/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8076 - val_loss: 0.4658 - val_accuracy: 0.7830\n",
            "Epoch 104/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8077 - val_loss: 0.4547 - val_accuracy: 0.7883\n",
            "Epoch 105/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8058 - val_loss: 0.4644 - val_accuracy: 0.7823\n",
            "Epoch 106/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8079 - val_loss: 0.4618 - val_accuracy: 0.7853\n",
            "Epoch 107/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8063 - val_loss: 0.4524 - val_accuracy: 0.7927\n",
            "Epoch 108/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8066 - val_loss: 0.4587 - val_accuracy: 0.7900\n",
            "Epoch 109/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8077 - val_loss: 0.4628 - val_accuracy: 0.7837\n",
            "Epoch 110/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8080 - val_loss: 0.4707 - val_accuracy: 0.7797\n",
            "Epoch 111/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8063 - val_loss: 0.4631 - val_accuracy: 0.7873\n",
            "Epoch 112/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8065 - val_loss: 0.4729 - val_accuracy: 0.7777\n",
            "Epoch 113/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8079 - val_loss: 0.4636 - val_accuracy: 0.7850\n",
            "Epoch 114/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8069 - val_loss: 0.4745 - val_accuracy: 0.7760\n",
            "Epoch 115/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8078 - val_loss: 0.4759 - val_accuracy: 0.7753\n",
            "Epoch 116/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8068 - val_loss: 0.4825 - val_accuracy: 0.7760\n",
            "Epoch 117/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8079 - val_loss: 0.4566 - val_accuracy: 0.7883\n",
            "Epoch 118/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8078 - val_loss: 0.4721 - val_accuracy: 0.7803\n",
            "Epoch 119/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8083 - val_loss: 0.4499 - val_accuracy: 0.7923\n",
            "Epoch 120/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8082 - val_loss: 0.4495 - val_accuracy: 0.7953\n",
            "Epoch 121/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8083 - val_loss: 0.4711 - val_accuracy: 0.7820\n",
            "Epoch 122/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8072 - val_loss: 0.4720 - val_accuracy: 0.7793\n",
            "Epoch 123/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8085 - val_loss: 0.4493 - val_accuracy: 0.7953\n",
            "Epoch 124/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8077 - val_loss: 0.4683 - val_accuracy: 0.7817\n",
            "Epoch 125/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8087 - val_loss: 0.4697 - val_accuracy: 0.7827\n",
            "Epoch 126/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8078 - val_loss: 0.4851 - val_accuracy: 0.7727\n",
            "Epoch 127/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8084 - val_loss: 0.4630 - val_accuracy: 0.7893\n",
            "Epoch 128/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8075 - val_loss: 0.4659 - val_accuracy: 0.7857\n",
            "Epoch 129/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8085 - val_loss: 0.4721 - val_accuracy: 0.7830\n",
            "Epoch 130/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8078 - val_loss: 0.4777 - val_accuracy: 0.7773\n",
            "Epoch 131/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8077 - val_loss: 0.4608 - val_accuracy: 0.7873\n",
            "Epoch 132/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8077 - val_loss: 0.4829 - val_accuracy: 0.7743\n",
            "Epoch 133/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8096 - val_loss: 0.4786 - val_accuracy: 0.7797\n",
            "Epoch 134/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8084 - val_loss: 0.4692 - val_accuracy: 0.7837\n",
            "Epoch 135/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8089 - val_loss: 0.4670 - val_accuracy: 0.7820\n",
            "Epoch 136/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8083 - val_loss: 0.4725 - val_accuracy: 0.7820\n",
            "Epoch 137/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8080 - val_loss: 0.4626 - val_accuracy: 0.7883\n",
            "Epoch 138/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8097 - val_loss: 0.4614 - val_accuracy: 0.7857\n",
            "Epoch 139/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8074 - val_loss: 0.4439 - val_accuracy: 0.7967\n",
            "Epoch 140/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8091 - val_loss: 0.4681 - val_accuracy: 0.7843\n",
            "Epoch 141/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8088 - val_loss: 0.4624 - val_accuracy: 0.7840\n",
            "Epoch 142/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8075 - val_loss: 0.4757 - val_accuracy: 0.7800\n",
            "Epoch 143/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8089 - val_loss: 0.4659 - val_accuracy: 0.7837\n",
            "Epoch 144/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8077 - val_loss: 0.4651 - val_accuracy: 0.7840\n",
            "Epoch 145/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8082 - val_loss: 0.4761 - val_accuracy: 0.7787\n",
            "Epoch 146/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8100 - val_loss: 0.4564 - val_accuracy: 0.7903\n",
            "Epoch 147/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8081 - val_loss: 0.4631 - val_accuracy: 0.7863\n",
            "Epoch 148/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8084 - val_loss: 0.4685 - val_accuracy: 0.7833\n",
            "Epoch 149/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4082 - accuracy: 0.8099 - val_loss: 0.4684 - val_accuracy: 0.7857\n",
            "Epoch 150/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8088 - val_loss: 0.4715 - val_accuracy: 0.7823\n",
            "Epoch 151/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8106 - val_loss: 0.4810 - val_accuracy: 0.7757\n",
            "Epoch 152/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8087 - val_loss: 0.4687 - val_accuracy: 0.7840\n",
            "Epoch 153/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8083 - val_loss: 0.4694 - val_accuracy: 0.7843\n",
            "Epoch 154/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8087 - val_loss: 0.4807 - val_accuracy: 0.7773\n",
            "Epoch 155/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8095 - val_loss: 0.4519 - val_accuracy: 0.7957\n",
            "Epoch 156/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4073 - accuracy: 0.8109 - val_loss: 0.4670 - val_accuracy: 0.7847\n",
            "Epoch 157/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8106 - val_loss: 0.4549 - val_accuracy: 0.7943\n",
            "Epoch 158/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8096 - val_loss: 0.4814 - val_accuracy: 0.7747\n",
            "Epoch 159/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4070 - accuracy: 0.8097 - val_loss: 0.4646 - val_accuracy: 0.7850\n",
            "Epoch 160/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8104 - val_loss: 0.4490 - val_accuracy: 0.7953\n",
            "Epoch 161/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8091 - val_loss: 0.4601 - val_accuracy: 0.7893\n",
            "Epoch 162/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8088 - val_loss: 0.4549 - val_accuracy: 0.7937\n",
            "Epoch 163/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8111 - val_loss: 0.4700 - val_accuracy: 0.7827\n",
            "Epoch 164/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4068 - accuracy: 0.8112 - val_loss: 0.4491 - val_accuracy: 0.7950\n",
            "Epoch 165/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8095 - val_loss: 0.4643 - val_accuracy: 0.7877\n",
            "Epoch 166/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8095 - val_loss: 0.4710 - val_accuracy: 0.7830\n",
            "Epoch 167/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8093 - val_loss: 0.4500 - val_accuracy: 0.7960\n",
            "Epoch 168/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4066 - accuracy: 0.8091 - val_loss: 0.4633 - val_accuracy: 0.7890\n",
            "Epoch 169/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8100 - val_loss: 0.4748 - val_accuracy: 0.7840\n",
            "Epoch 170/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4065 - accuracy: 0.8089 - val_loss: 0.4555 - val_accuracy: 0.7930\n",
            "Epoch 171/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8104 - val_loss: 0.4650 - val_accuracy: 0.7847\n",
            "Epoch 172/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8110 - val_loss: 0.4559 - val_accuracy: 0.7930\n",
            "Epoch 173/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8105 - val_loss: 0.4678 - val_accuracy: 0.7837\n",
            "Epoch 174/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4065 - accuracy: 0.8099 - val_loss: 0.4735 - val_accuracy: 0.7820\n",
            "Epoch 175/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8109 - val_loss: 0.4774 - val_accuracy: 0.7783\n",
            "Epoch 176/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8106 - val_loss: 0.4784 - val_accuracy: 0.7790\n",
            "Epoch 177/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8111 - val_loss: 0.4691 - val_accuracy: 0.7840\n",
            "Epoch 178/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8106 - val_loss: 0.4669 - val_accuracy: 0.7873\n",
            "Epoch 179/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8121 - val_loss: 0.4756 - val_accuracy: 0.7823\n",
            "Epoch 180/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8099 - val_loss: 0.4725 - val_accuracy: 0.7817\n",
            "Epoch 181/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8124 - val_loss: 0.4628 - val_accuracy: 0.7897\n",
            "Epoch 182/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8096 - val_loss: 0.4795 - val_accuracy: 0.7827\n",
            "Epoch 183/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8119 - val_loss: 0.4672 - val_accuracy: 0.7887\n",
            "Epoch 184/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8113 - val_loss: 0.4583 - val_accuracy: 0.7930\n",
            "Epoch 185/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8096 - val_loss: 0.4760 - val_accuracy: 0.7827\n",
            "Epoch 186/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8127 - val_loss: 0.4800 - val_accuracy: 0.7790\n",
            "Epoch 187/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8098 - val_loss: 0.4609 - val_accuracy: 0.7913\n",
            "Epoch 188/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8104 - val_loss: 0.4586 - val_accuracy: 0.7933\n",
            "Epoch 189/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8085 - val_loss: 0.4506 - val_accuracy: 0.7970\n",
            "Epoch 190/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8124 - val_loss: 0.4605 - val_accuracy: 0.7927\n",
            "Epoch 191/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8106 - val_loss: 0.4432 - val_accuracy: 0.7990\n",
            "Epoch 192/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8087 - val_loss: 0.4575 - val_accuracy: 0.7953\n",
            "Epoch 193/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8084 - val_loss: 0.4582 - val_accuracy: 0.7910\n",
            "Epoch 194/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4057 - accuracy: 0.8113 - val_loss: 0.4621 - val_accuracy: 0.7927\n",
            "Epoch 195/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8101 - val_loss: 0.4673 - val_accuracy: 0.7887\n",
            "Epoch 196/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.8091 - val_loss: 0.4595 - val_accuracy: 0.7933\n",
            "Epoch 197/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4055 - accuracy: 0.8115 - val_loss: 0.4754 - val_accuracy: 0.7827\n",
            "Epoch 198/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8114 - val_loss: 0.4620 - val_accuracy: 0.7910\n",
            "Epoch 199/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8111 - val_loss: 0.4698 - val_accuracy: 0.7880\n",
            "Epoch 200/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8097 - val_loss: 0.4778 - val_accuracy: 0.7810\n",
            "Epoch 201/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8106 - val_loss: 0.4612 - val_accuracy: 0.7930\n",
            "Epoch 202/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8100 - val_loss: 0.4580 - val_accuracy: 0.7940\n",
            "Epoch 203/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4049 - accuracy: 0.8082 - val_loss: 0.4503 - val_accuracy: 0.7947\n",
            "Epoch 204/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8084 - val_loss: 0.4824 - val_accuracy: 0.7807\n",
            "Epoch 205/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4056 - accuracy: 0.8094 - val_loss: 0.4591 - val_accuracy: 0.7950\n",
            "Epoch 206/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8104 - val_loss: 0.4772 - val_accuracy: 0.7823\n",
            "Epoch 207/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8105 - val_loss: 0.4587 - val_accuracy: 0.7930\n",
            "Epoch 208/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4054 - accuracy: 0.8110 - val_loss: 0.4537 - val_accuracy: 0.7953\n",
            "Epoch 209/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4050 - accuracy: 0.8112 - val_loss: 0.4647 - val_accuracy: 0.7923\n",
            "Epoch 210/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4055 - accuracy: 0.8087 - val_loss: 0.4626 - val_accuracy: 0.7913\n",
            "Epoch 211/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4048 - accuracy: 0.8090 - val_loss: 0.4434 - val_accuracy: 0.8007\n",
            "Epoch 212/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4054 - accuracy: 0.8122 - val_loss: 0.4663 - val_accuracy: 0.7873\n",
            "Epoch 213/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4051 - accuracy: 0.8106 - val_loss: 0.4516 - val_accuracy: 0.7987\n",
            "Epoch 214/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4049 - accuracy: 0.8100 - val_loss: 0.4683 - val_accuracy: 0.7890\n",
            "Epoch 215/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4051 - accuracy: 0.8087 - val_loss: 0.4777 - val_accuracy: 0.7807\n",
            "Epoch 216/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4048 - accuracy: 0.8113 - val_loss: 0.4640 - val_accuracy: 0.7910\n",
            "Epoch 217/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4047 - accuracy: 0.8102 - val_loss: 0.4633 - val_accuracy: 0.7917\n",
            "Epoch 218/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4049 - accuracy: 0.8111 - val_loss: 0.4747 - val_accuracy: 0.7837\n",
            "Epoch 219/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4050 - accuracy: 0.8115 - val_loss: 0.4578 - val_accuracy: 0.7937\n",
            "Epoch 220/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8106 - val_loss: 0.4660 - val_accuracy: 0.7903\n",
            "Epoch 221/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4045 - accuracy: 0.8102 - val_loss: 0.4896 - val_accuracy: 0.7773\n",
            "Epoch 222/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8107 - val_loss: 0.4564 - val_accuracy: 0.7947\n",
            "Epoch 223/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8108 - val_loss: 0.4736 - val_accuracy: 0.7833\n",
            "Epoch 224/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4047 - accuracy: 0.8111 - val_loss: 0.4552 - val_accuracy: 0.7947\n",
            "Epoch 225/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4046 - accuracy: 0.8096 - val_loss: 0.4554 - val_accuracy: 0.7960\n",
            "Epoch 226/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8094 - val_loss: 0.4601 - val_accuracy: 0.7913\n",
            "Epoch 227/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8102 - val_loss: 0.4713 - val_accuracy: 0.7850\n",
            "Epoch 228/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4043 - accuracy: 0.8111 - val_loss: 0.4706 - val_accuracy: 0.7847\n",
            "Epoch 229/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4041 - accuracy: 0.8102 - val_loss: 0.4671 - val_accuracy: 0.7873\n",
            "Epoch 230/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8107 - val_loss: 0.4574 - val_accuracy: 0.7957\n",
            "Epoch 231/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8113 - val_loss: 0.4665 - val_accuracy: 0.7897\n",
            "Epoch 232/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4040 - accuracy: 0.8102 - val_loss: 0.4595 - val_accuracy: 0.7893\n",
            "Epoch 233/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8125 - val_loss: 0.4711 - val_accuracy: 0.7867\n",
            "Epoch 234/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8108 - val_loss: 0.4739 - val_accuracy: 0.7837\n",
            "Epoch 235/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4043 - accuracy: 0.8101 - val_loss: 0.4689 - val_accuracy: 0.7850\n",
            "Epoch 236/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.8097 - val_loss: 0.4888 - val_accuracy: 0.7773\n",
            "Epoch 237/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8109 - val_loss: 0.4407 - val_accuracy: 0.8030\n",
            "Epoch 238/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8116 - val_loss: 0.4616 - val_accuracy: 0.7913\n",
            "Epoch 239/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8129 - val_loss: 0.4542 - val_accuracy: 0.7977\n",
            "Epoch 240/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8108 - val_loss: 0.4540 - val_accuracy: 0.7943\n",
            "Epoch 241/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4038 - accuracy: 0.8092 - val_loss: 0.4521 - val_accuracy: 0.7960\n",
            "Epoch 242/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.8118 - val_loss: 0.4505 - val_accuracy: 0.7980\n",
            "Epoch 243/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4036 - accuracy: 0.8119 - val_loss: 0.4739 - val_accuracy: 0.7840\n",
            "Epoch 244/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8111 - val_loss: 0.4770 - val_accuracy: 0.7800\n",
            "Epoch 245/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8083 - val_loss: 0.4695 - val_accuracy: 0.7873\n",
            "Epoch 246/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4032 - accuracy: 0.8116 - val_loss: 0.4713 - val_accuracy: 0.7863\n",
            "Epoch 247/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4037 - accuracy: 0.8118 - val_loss: 0.4734 - val_accuracy: 0.7863\n",
            "Epoch 248/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8107 - val_loss: 0.4671 - val_accuracy: 0.7907\n",
            "Epoch 249/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8103 - val_loss: 0.4747 - val_accuracy: 0.7857\n",
            "Epoch 250/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8113 - val_loss: 0.4676 - val_accuracy: 0.7913\n",
            "Epoch 251/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8123 - val_loss: 0.4768 - val_accuracy: 0.7867\n",
            "Epoch 252/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4030 - accuracy: 0.8103 - val_loss: 0.4446 - val_accuracy: 0.8010\n",
            "Epoch 253/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8104 - val_loss: 0.4676 - val_accuracy: 0.7913\n",
            "Epoch 254/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8106 - val_loss: 0.4408 - val_accuracy: 0.8020\n",
            "Epoch 255/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8099 - val_loss: 0.4692 - val_accuracy: 0.7903\n",
            "Epoch 256/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8110 - val_loss: 0.4502 - val_accuracy: 0.7983\n",
            "Epoch 257/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8099 - val_loss: 0.4742 - val_accuracy: 0.7863\n",
            "Epoch 258/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8117 - val_loss: 0.4625 - val_accuracy: 0.7923\n",
            "Epoch 259/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4031 - accuracy: 0.8111 - val_loss: 0.4772 - val_accuracy: 0.7850\n",
            "Epoch 260/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8111 - val_loss: 0.4549 - val_accuracy: 0.7983\n",
            "Epoch 261/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8106 - val_loss: 0.4604 - val_accuracy: 0.7943\n",
            "Epoch 262/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8123 - val_loss: 0.4659 - val_accuracy: 0.7927\n",
            "Epoch 263/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4027 - accuracy: 0.8115 - val_loss: 0.4607 - val_accuracy: 0.7933\n",
            "Epoch 264/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.8115 - val_loss: 0.4478 - val_accuracy: 0.8023\n",
            "Epoch 265/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8100 - val_loss: 0.4617 - val_accuracy: 0.7913\n",
            "Epoch 266/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8110 - val_loss: 0.4585 - val_accuracy: 0.7960\n",
            "Epoch 267/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8105 - val_loss: 0.4504 - val_accuracy: 0.7983\n",
            "Epoch 268/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8107 - val_loss: 0.4619 - val_accuracy: 0.7910\n",
            "Epoch 269/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8115 - val_loss: 0.4519 - val_accuracy: 0.7987\n",
            "Epoch 270/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8137 - val_loss: 0.4505 - val_accuracy: 0.7973\n",
            "Epoch 271/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4029 - accuracy: 0.8128 - val_loss: 0.4837 - val_accuracy: 0.7797\n",
            "Epoch 272/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8120 - val_loss: 0.4423 - val_accuracy: 0.8047\n",
            "Epoch 273/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4027 - accuracy: 0.8106 - val_loss: 0.4712 - val_accuracy: 0.7867\n",
            "Epoch 274/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8140 - val_loss: 0.4752 - val_accuracy: 0.7843\n",
            "Epoch 275/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4025 - accuracy: 0.8118 - val_loss: 0.4526 - val_accuracy: 0.7977\n",
            "Epoch 276/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8130 - val_loss: 0.4736 - val_accuracy: 0.7830\n",
            "Epoch 277/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4029 - accuracy: 0.8141 - val_loss: 0.4552 - val_accuracy: 0.7980\n",
            "Epoch 278/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8109 - val_loss: 0.4782 - val_accuracy: 0.7817\n",
            "Epoch 279/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4033 - accuracy: 0.8130 - val_loss: 0.4629 - val_accuracy: 0.7923\n",
            "Epoch 280/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8136 - val_loss: 0.4793 - val_accuracy: 0.7857\n",
            "Epoch 281/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4020 - accuracy: 0.8123 - val_loss: 0.4517 - val_accuracy: 0.7970\n",
            "Epoch 282/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8121 - val_loss: 0.4639 - val_accuracy: 0.7923\n",
            "Epoch 283/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4022 - accuracy: 0.8104 - val_loss: 0.4504 - val_accuracy: 0.7987\n",
            "Epoch 284/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8117 - val_loss: 0.4725 - val_accuracy: 0.7887\n",
            "Epoch 285/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8117 - val_loss: 0.4598 - val_accuracy: 0.7943\n",
            "Epoch 286/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8121 - val_loss: 0.4490 - val_accuracy: 0.8007\n",
            "Epoch 287/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8115 - val_loss: 0.4582 - val_accuracy: 0.7943\n",
            "Epoch 288/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8115 - val_loss: 0.4666 - val_accuracy: 0.7923\n",
            "Epoch 289/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8113 - val_loss: 0.4629 - val_accuracy: 0.7920\n",
            "Epoch 290/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8115 - val_loss: 0.4600 - val_accuracy: 0.7953\n",
            "Epoch 291/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8114 - val_loss: 0.4634 - val_accuracy: 0.7930\n",
            "Epoch 292/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8111 - val_loss: 0.4949 - val_accuracy: 0.7727\n",
            "Epoch 293/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4019 - accuracy: 0.8093 - val_loss: 0.4783 - val_accuracy: 0.7837\n",
            "Epoch 294/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.8134 - val_loss: 0.4807 - val_accuracy: 0.7793\n",
            "Epoch 295/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8112 - val_loss: 0.4657 - val_accuracy: 0.7893\n",
            "Epoch 296/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4023 - accuracy: 0.8124 - val_loss: 0.4601 - val_accuracy: 0.7920\n",
            "Epoch 297/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4012 - accuracy: 0.8129 - val_loss: 0.4379 - val_accuracy: 0.8080\n",
            "Epoch 298/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4022 - accuracy: 0.8125 - val_loss: 0.4646 - val_accuracy: 0.7930\n",
            "Epoch 299/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4016 - accuracy: 0.8120 - val_loss: 0.4533 - val_accuracy: 0.7997\n",
            "Epoch 300/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4015 - accuracy: 0.8122 - val_loss: 0.4662 - val_accuracy: 0.7903\n",
            "Epoch 301/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4012 - accuracy: 0.8108 - val_loss: 0.4628 - val_accuracy: 0.7903\n",
            "Epoch 302/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8110 - val_loss: 0.4594 - val_accuracy: 0.7947\n",
            "Epoch 303/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4015 - accuracy: 0.8119 - val_loss: 0.4589 - val_accuracy: 0.7943\n",
            "Epoch 304/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8118 - val_loss: 0.4534 - val_accuracy: 0.8003\n",
            "Epoch 305/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4009 - accuracy: 0.8125 - val_loss: 0.4636 - val_accuracy: 0.7913\n",
            "Epoch 306/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4008 - accuracy: 0.8127 - val_loss: 0.4686 - val_accuracy: 0.7890\n",
            "Epoch 307/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8122 - val_loss: 0.4453 - val_accuracy: 0.8020\n",
            "Epoch 308/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4007 - accuracy: 0.8114 - val_loss: 0.4536 - val_accuracy: 0.7960\n",
            "Epoch 309/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4009 - accuracy: 0.8124 - val_loss: 0.4728 - val_accuracy: 0.7870\n",
            "Epoch 310/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8118 - val_loss: 0.4694 - val_accuracy: 0.7870\n",
            "Epoch 311/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4008 - accuracy: 0.8124 - val_loss: 0.4617 - val_accuracy: 0.7903\n",
            "Epoch 312/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4004 - accuracy: 0.8125 - val_loss: 0.4701 - val_accuracy: 0.7877\n",
            "Epoch 313/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4006 - accuracy: 0.8123 - val_loss: 0.4525 - val_accuracy: 0.7963\n",
            "Epoch 314/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8117 - val_loss: 0.4597 - val_accuracy: 0.7903\n",
            "Epoch 315/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8124 - val_loss: 0.4557 - val_accuracy: 0.7947\n",
            "Epoch 316/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4001 - accuracy: 0.8135 - val_loss: 0.4605 - val_accuracy: 0.7897\n",
            "Epoch 317/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4005 - accuracy: 0.8140 - val_loss: 0.4666 - val_accuracy: 0.7880\n",
            "Epoch 318/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4007 - accuracy: 0.8131 - val_loss: 0.4564 - val_accuracy: 0.7953\n",
            "Epoch 319/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4002 - accuracy: 0.8113 - val_loss: 0.4634 - val_accuracy: 0.7920\n",
            "Epoch 320/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3999 - accuracy: 0.8147 - val_loss: 0.4579 - val_accuracy: 0.7947\n",
            "Epoch 321/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4001 - accuracy: 0.8118 - val_loss: 0.4604 - val_accuracy: 0.7933\n",
            "Epoch 322/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3999 - accuracy: 0.8141 - val_loss: 0.4661 - val_accuracy: 0.7897\n",
            "Epoch 323/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.4005 - accuracy: 0.8141 - val_loss: 0.4624 - val_accuracy: 0.7927\n",
            "Epoch 324/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3997 - accuracy: 0.8130 - val_loss: 0.4569 - val_accuracy: 0.7977\n",
            "Epoch 325/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3995 - accuracy: 0.8130 - val_loss: 0.4461 - val_accuracy: 0.8020\n",
            "Epoch 326/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3995 - accuracy: 0.8126 - val_loss: 0.4664 - val_accuracy: 0.7913\n",
            "Epoch 327/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3996 - accuracy: 0.8116 - val_loss: 0.4417 - val_accuracy: 0.8047\n",
            "Epoch 328/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3996 - accuracy: 0.8121 - val_loss: 0.4524 - val_accuracy: 0.7980\n",
            "Epoch 329/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3999 - accuracy: 0.8130 - val_loss: 0.4457 - val_accuracy: 0.8003\n",
            "Epoch 330/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3993 - accuracy: 0.8134 - val_loss: 0.4558 - val_accuracy: 0.7940\n",
            "Epoch 331/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3991 - accuracy: 0.8143 - val_loss: 0.4622 - val_accuracy: 0.7923\n",
            "Epoch 332/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3993 - accuracy: 0.8128 - val_loss: 0.4551 - val_accuracy: 0.7940\n",
            "Epoch 333/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3993 - accuracy: 0.8135 - val_loss: 0.4663 - val_accuracy: 0.7920\n",
            "Epoch 334/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3995 - accuracy: 0.8125 - val_loss: 0.4621 - val_accuracy: 0.7927\n",
            "Epoch 335/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3991 - accuracy: 0.8122 - val_loss: 0.4549 - val_accuracy: 0.7937\n",
            "Epoch 336/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3996 - accuracy: 0.8135 - val_loss: 0.4849 - val_accuracy: 0.7803\n",
            "Epoch 337/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3997 - accuracy: 0.8133 - val_loss: 0.4547 - val_accuracy: 0.7950\n",
            "Epoch 338/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8143 - val_loss: 0.4589 - val_accuracy: 0.7940\n",
            "Epoch 339/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3990 - accuracy: 0.8147 - val_loss: 0.4594 - val_accuracy: 0.7943\n",
            "Epoch 340/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3990 - accuracy: 0.8140 - val_loss: 0.4463 - val_accuracy: 0.8013\n",
            "Epoch 341/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3989 - accuracy: 0.8134 - val_loss: 0.4719 - val_accuracy: 0.7850\n",
            "Epoch 342/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8152 - val_loss: 0.4737 - val_accuracy: 0.7830\n",
            "Epoch 343/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8148 - val_loss: 0.4554 - val_accuracy: 0.7970\n",
            "Epoch 344/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8116 - val_loss: 0.4669 - val_accuracy: 0.7890\n",
            "Epoch 345/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3990 - accuracy: 0.8125 - val_loss: 0.4571 - val_accuracy: 0.7940\n",
            "Epoch 346/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8145 - val_loss: 0.4601 - val_accuracy: 0.7917\n",
            "Epoch 347/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3992 - accuracy: 0.8133 - val_loss: 0.4553 - val_accuracy: 0.7953\n",
            "Epoch 348/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3987 - accuracy: 0.8138 - val_loss: 0.4575 - val_accuracy: 0.7930\n",
            "Epoch 349/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3990 - accuracy: 0.8136 - val_loss: 0.4586 - val_accuracy: 0.7917\n",
            "Epoch 350/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3988 - accuracy: 0.8126 - val_loss: 0.4449 - val_accuracy: 0.7993\n",
            "Epoch 351/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3992 - accuracy: 0.8110 - val_loss: 0.4491 - val_accuracy: 0.7970\n",
            "Epoch 352/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8144 - val_loss: 0.4516 - val_accuracy: 0.7973\n",
            "Epoch 353/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3990 - accuracy: 0.8125 - val_loss: 0.4395 - val_accuracy: 0.8027\n",
            "Epoch 354/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8142 - val_loss: 0.4486 - val_accuracy: 0.7963\n",
            "Epoch 355/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8126 - val_loss: 0.4614 - val_accuracy: 0.7903\n",
            "Epoch 356/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8135 - val_loss: 0.4666 - val_accuracy: 0.7903\n",
            "Epoch 357/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3990 - accuracy: 0.8134 - val_loss: 0.4643 - val_accuracy: 0.7910\n",
            "Epoch 358/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8150 - val_loss: 0.4447 - val_accuracy: 0.7997\n",
            "Epoch 359/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3987 - accuracy: 0.8134 - val_loss: 0.4644 - val_accuracy: 0.7883\n",
            "Epoch 360/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3986 - accuracy: 0.8142 - val_loss: 0.4565 - val_accuracy: 0.7937\n",
            "Epoch 361/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8137 - val_loss: 0.4453 - val_accuracy: 0.7970\n",
            "Epoch 362/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3984 - accuracy: 0.8134 - val_loss: 0.4531 - val_accuracy: 0.7933\n",
            "Epoch 363/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8116 - val_loss: 0.4405 - val_accuracy: 0.8010\n",
            "Epoch 364/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8121 - val_loss: 0.4464 - val_accuracy: 0.7990\n",
            "Epoch 365/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3986 - accuracy: 0.8150 - val_loss: 0.4523 - val_accuracy: 0.7970\n",
            "Epoch 366/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3983 - accuracy: 0.8140 - val_loss: 0.4422 - val_accuracy: 0.7990\n",
            "Epoch 367/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3981 - accuracy: 0.8134 - val_loss: 0.4354 - val_accuracy: 0.8050\n",
            "Epoch 368/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3988 - accuracy: 0.8124 - val_loss: 0.4607 - val_accuracy: 0.7910\n",
            "Epoch 369/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8140 - val_loss: 0.4551 - val_accuracy: 0.7933\n",
            "Epoch 370/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3986 - accuracy: 0.8135 - val_loss: 0.4558 - val_accuracy: 0.7933\n",
            "Epoch 371/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8144 - val_loss: 0.4786 - val_accuracy: 0.7797\n",
            "Epoch 372/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8126 - val_loss: 0.4755 - val_accuracy: 0.7827\n",
            "Epoch 373/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3985 - accuracy: 0.8146 - val_loss: 0.4539 - val_accuracy: 0.7953\n",
            "Epoch 374/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3980 - accuracy: 0.8135 - val_loss: 0.4581 - val_accuracy: 0.7937\n",
            "Epoch 375/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8127 - val_loss: 0.4597 - val_accuracy: 0.7903\n",
            "Epoch 376/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3982 - accuracy: 0.8130 - val_loss: 0.4510 - val_accuracy: 0.7950\n",
            "Epoch 377/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3981 - accuracy: 0.8130 - val_loss: 0.4431 - val_accuracy: 0.7997\n",
            "Epoch 378/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8134 - val_loss: 0.4616 - val_accuracy: 0.7897\n",
            "Epoch 379/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8130 - val_loss: 0.4740 - val_accuracy: 0.7817\n",
            "Epoch 380/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3985 - accuracy: 0.8148 - val_loss: 0.4549 - val_accuracy: 0.7940\n",
            "Epoch 381/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8128 - val_loss: 0.4628 - val_accuracy: 0.7880\n",
            "Epoch 382/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8126 - val_loss: 0.4498 - val_accuracy: 0.7950\n",
            "Epoch 383/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8136 - val_loss: 0.4478 - val_accuracy: 0.7963\n",
            "Epoch 384/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3984 - accuracy: 0.8137 - val_loss: 0.4628 - val_accuracy: 0.7900\n",
            "Epoch 385/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3979 - accuracy: 0.8127 - val_loss: 0.4571 - val_accuracy: 0.7927\n",
            "Epoch 386/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3979 - accuracy: 0.8146 - val_loss: 0.4524 - val_accuracy: 0.7943\n",
            "Epoch 387/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3982 - accuracy: 0.8131 - val_loss: 0.4682 - val_accuracy: 0.7880\n",
            "Epoch 388/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3981 - accuracy: 0.8149 - val_loss: 0.4501 - val_accuracy: 0.7967\n",
            "Epoch 389/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8134 - val_loss: 0.4639 - val_accuracy: 0.7887\n",
            "Epoch 390/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3984 - accuracy: 0.8129 - val_loss: 0.4697 - val_accuracy: 0.7837\n",
            "Epoch 391/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3983 - accuracy: 0.8142 - val_loss: 0.4727 - val_accuracy: 0.7817\n",
            "Epoch 392/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3977 - accuracy: 0.8151 - val_loss: 0.4478 - val_accuracy: 0.8007\n",
            "Epoch 393/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3983 - accuracy: 0.8159 - val_loss: 0.4696 - val_accuracy: 0.7877\n",
            "Epoch 394/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3985 - accuracy: 0.8129 - val_loss: 0.4528 - val_accuracy: 0.7967\n",
            "Epoch 395/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3979 - accuracy: 0.8146 - val_loss: 0.4453 - val_accuracy: 0.8017\n",
            "Epoch 396/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.8126 - val_loss: 0.4471 - val_accuracy: 0.7993\n",
            "Epoch 397/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3980 - accuracy: 0.8136 - val_loss: 0.4616 - val_accuracy: 0.7933\n",
            "Epoch 398/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3978 - accuracy: 0.8144 - val_loss: 0.4621 - val_accuracy: 0.7870\n",
            "Epoch 399/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3978 - accuracy: 0.8141 - val_loss: 0.4451 - val_accuracy: 0.8010\n",
            "Epoch 400/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3979 - accuracy: 0.8148 - val_loss: 0.4594 - val_accuracy: 0.7903\n",
            "Epoch 401/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3978 - accuracy: 0.8124 - val_loss: 0.4423 - val_accuracy: 0.8010\n",
            "Epoch 402/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3981 - accuracy: 0.8139 - val_loss: 0.4484 - val_accuracy: 0.7987\n",
            "Epoch 403/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3975 - accuracy: 0.8146 - val_loss: 0.4448 - val_accuracy: 0.8010\n",
            "Epoch 404/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3979 - accuracy: 0.8153 - val_loss: 0.4620 - val_accuracy: 0.7910\n",
            "Epoch 405/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.8125 - val_loss: 0.4568 - val_accuracy: 0.7910\n",
            "Epoch 406/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3980 - accuracy: 0.8136 - val_loss: 0.4489 - val_accuracy: 0.7983\n",
            "Epoch 407/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3983 - accuracy: 0.8143 - val_loss: 0.4622 - val_accuracy: 0.7913\n",
            "Epoch 408/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3980 - accuracy: 0.8146 - val_loss: 0.4533 - val_accuracy: 0.7947\n",
            "Epoch 409/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3979 - accuracy: 0.8146 - val_loss: 0.4480 - val_accuracy: 0.7970\n",
            "Epoch 410/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3978 - accuracy: 0.8133 - val_loss: 0.4422 - val_accuracy: 0.8017\n",
            "Epoch 411/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8158 - val_loss: 0.4724 - val_accuracy: 0.7810\n",
            "Epoch 412/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3976 - accuracy: 0.8130 - val_loss: 0.4540 - val_accuracy: 0.7920\n",
            "Epoch 413/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3976 - accuracy: 0.8126 - val_loss: 0.4708 - val_accuracy: 0.7810\n",
            "Epoch 414/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3978 - accuracy: 0.8135 - val_loss: 0.4521 - val_accuracy: 0.7980\n",
            "Epoch 415/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8140 - val_loss: 0.4570 - val_accuracy: 0.7927\n",
            "Epoch 416/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3981 - accuracy: 0.8140 - val_loss: 0.4579 - val_accuracy: 0.7920\n",
            "Epoch 417/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8125 - val_loss: 0.4528 - val_accuracy: 0.7953\n",
            "Epoch 418/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3974 - accuracy: 0.8142 - val_loss: 0.4572 - val_accuracy: 0.7910\n",
            "Epoch 419/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3975 - accuracy: 0.8132 - val_loss: 0.4561 - val_accuracy: 0.7917\n",
            "Epoch 420/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3974 - accuracy: 0.8129 - val_loss: 0.4490 - val_accuracy: 0.7943\n",
            "Epoch 421/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8142 - val_loss: 0.4481 - val_accuracy: 0.7990\n",
            "Epoch 422/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3976 - accuracy: 0.8126 - val_loss: 0.4586 - val_accuracy: 0.7887\n",
            "Epoch 423/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3975 - accuracy: 0.8134 - val_loss: 0.4588 - val_accuracy: 0.7910\n",
            "Epoch 424/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3979 - accuracy: 0.8130 - val_loss: 0.4517 - val_accuracy: 0.7950\n",
            "Epoch 425/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3976 - accuracy: 0.8135 - val_loss: 0.4518 - val_accuracy: 0.7917\n",
            "Epoch 426/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3976 - accuracy: 0.8141 - val_loss: 0.4701 - val_accuracy: 0.7823\n",
            "Epoch 427/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3974 - accuracy: 0.8137 - val_loss: 0.4769 - val_accuracy: 0.7777\n",
            "Epoch 428/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3973 - accuracy: 0.8144 - val_loss: 0.4693 - val_accuracy: 0.7853\n",
            "Epoch 429/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3975 - accuracy: 0.8132 - val_loss: 0.4620 - val_accuracy: 0.7847\n",
            "Epoch 430/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3974 - accuracy: 0.8147 - val_loss: 0.4603 - val_accuracy: 0.7873\n",
            "Epoch 431/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3977 - accuracy: 0.8119 - val_loss: 0.4479 - val_accuracy: 0.7940\n",
            "Epoch 432/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3970 - accuracy: 0.8147 - val_loss: 0.4524 - val_accuracy: 0.7920\n",
            "Epoch 433/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3973 - accuracy: 0.8135 - val_loss: 0.4656 - val_accuracy: 0.7833\n",
            "Epoch 434/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3971 - accuracy: 0.8135 - val_loss: 0.4531 - val_accuracy: 0.7920\n",
            "Epoch 435/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3971 - accuracy: 0.8124 - val_loss: 0.4493 - val_accuracy: 0.7953\n",
            "Epoch 436/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3970 - accuracy: 0.8143 - val_loss: 0.4505 - val_accuracy: 0.7957\n",
            "Epoch 437/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3972 - accuracy: 0.8133 - val_loss: 0.4356 - val_accuracy: 0.8023\n",
            "Epoch 438/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3973 - accuracy: 0.8139 - val_loss: 0.4578 - val_accuracy: 0.7877\n",
            "Epoch 439/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3972 - accuracy: 0.8139 - val_loss: 0.4765 - val_accuracy: 0.7773\n",
            "Epoch 440/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3968 - accuracy: 0.8150 - val_loss: 0.4510 - val_accuracy: 0.7897\n",
            "Epoch 441/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3972 - accuracy: 0.8141 - val_loss: 0.4415 - val_accuracy: 0.8000\n",
            "Epoch 442/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3966 - accuracy: 0.8138 - val_loss: 0.4614 - val_accuracy: 0.7870\n",
            "Epoch 443/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3968 - accuracy: 0.8135 - val_loss: 0.4649 - val_accuracy: 0.7830\n",
            "Epoch 444/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3966 - accuracy: 0.8115 - val_loss: 0.4617 - val_accuracy: 0.7833\n",
            "Epoch 445/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3972 - accuracy: 0.8140 - val_loss: 0.4542 - val_accuracy: 0.7867\n",
            "Epoch 446/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3971 - accuracy: 0.8125 - val_loss: 0.4517 - val_accuracy: 0.7877\n",
            "Epoch 447/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3966 - accuracy: 0.8138 - val_loss: 0.4331 - val_accuracy: 0.8013\n",
            "Epoch 448/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3966 - accuracy: 0.8134 - val_loss: 0.4601 - val_accuracy: 0.7857\n",
            "Epoch 449/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3971 - accuracy: 0.8128 - val_loss: 0.4539 - val_accuracy: 0.7927\n",
            "Epoch 450/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3969 - accuracy: 0.8095 - val_loss: 0.4582 - val_accuracy: 0.7870\n",
            "Epoch 451/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3971 - accuracy: 0.8135 - val_loss: 0.4641 - val_accuracy: 0.7860\n",
            "Epoch 452/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3967 - accuracy: 0.8126 - val_loss: 0.4650 - val_accuracy: 0.7843\n",
            "Epoch 453/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3963 - accuracy: 0.8134 - val_loss: 0.4511 - val_accuracy: 0.7947\n",
            "Epoch 454/500\n",
            "173/173 [==============================] - 0s 3ms/step - loss: 0.3967 - accuracy: 0.8135 - val_loss: 0.4670 - val_accuracy: 0.7837\n",
            "Epoch 455/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3968 - accuracy: 0.8145 - val_loss: 0.4605 - val_accuracy: 0.7893\n",
            "Epoch 456/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3970 - accuracy: 0.8124 - val_loss: 0.4652 - val_accuracy: 0.7860\n",
            "Epoch 457/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3967 - accuracy: 0.8144 - val_loss: 0.4617 - val_accuracy: 0.7893\n",
            "Epoch 458/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3960 - accuracy: 0.8134 - val_loss: 0.4348 - val_accuracy: 0.8003\n",
            "Epoch 459/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3966 - accuracy: 0.8145 - val_loss: 0.4524 - val_accuracy: 0.7897\n",
            "Epoch 460/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3964 - accuracy: 0.8149 - val_loss: 0.4618 - val_accuracy: 0.7853\n",
            "Epoch 461/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3968 - accuracy: 0.8120 - val_loss: 0.4510 - val_accuracy: 0.7940\n",
            "Epoch 462/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3964 - accuracy: 0.8128 - val_loss: 0.4556 - val_accuracy: 0.7890\n",
            "Epoch 463/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3965 - accuracy: 0.8135 - val_loss: 0.4539 - val_accuracy: 0.7937\n",
            "Epoch 464/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3961 - accuracy: 0.8145 - val_loss: 0.4459 - val_accuracy: 0.7963\n",
            "Epoch 465/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3965 - accuracy: 0.8128 - val_loss: 0.4439 - val_accuracy: 0.7953\n",
            "Epoch 466/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3965 - accuracy: 0.8137 - val_loss: 0.4465 - val_accuracy: 0.7963\n",
            "Epoch 467/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3961 - accuracy: 0.8124 - val_loss: 0.4554 - val_accuracy: 0.7890\n",
            "Epoch 468/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3960 - accuracy: 0.8133 - val_loss: 0.4731 - val_accuracy: 0.7780\n",
            "Epoch 469/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3967 - accuracy: 0.8141 - val_loss: 0.4521 - val_accuracy: 0.7887\n",
            "Epoch 470/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3966 - accuracy: 0.8146 - val_loss: 0.4701 - val_accuracy: 0.7823\n",
            "Epoch 471/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3963 - accuracy: 0.8140 - val_loss: 0.4535 - val_accuracy: 0.7930\n",
            "Epoch 472/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3959 - accuracy: 0.8152 - val_loss: 0.4598 - val_accuracy: 0.7880\n",
            "Epoch 473/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3960 - accuracy: 0.8159 - val_loss: 0.4481 - val_accuracy: 0.7967\n",
            "Epoch 474/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3963 - accuracy: 0.8133 - val_loss: 0.4503 - val_accuracy: 0.7937\n",
            "Epoch 475/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3960 - accuracy: 0.8141 - val_loss: 0.4568 - val_accuracy: 0.7897\n",
            "Epoch 476/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3962 - accuracy: 0.8142 - val_loss: 0.4580 - val_accuracy: 0.7907\n",
            "Epoch 477/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3962 - accuracy: 0.8144 - val_loss: 0.4796 - val_accuracy: 0.7797\n",
            "Epoch 478/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3962 - accuracy: 0.8148 - val_loss: 0.4493 - val_accuracy: 0.7960\n",
            "Epoch 479/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3961 - accuracy: 0.8147 - val_loss: 0.4464 - val_accuracy: 0.7957\n",
            "Epoch 480/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3959 - accuracy: 0.8146 - val_loss: 0.4560 - val_accuracy: 0.7897\n",
            "Epoch 481/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3960 - accuracy: 0.8138 - val_loss: 0.4571 - val_accuracy: 0.7907\n",
            "Epoch 482/500\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 0.3963 - accuracy: 0.8130 - val_loss: 0.4459 - val_accuracy: 0.7990\n",
            "Epoch 483/500\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 0.3959 - accuracy: 0.8151 - val_loss: 0.4673 - val_accuracy: 0.7857\n",
            "Epoch 484/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3961 - accuracy: 0.8140 - val_loss: 0.4637 - val_accuracy: 0.7867\n",
            "Epoch 485/500\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 0.3956 - accuracy: 0.8145 - val_loss: 0.4278 - val_accuracy: 0.8050\n",
            "Epoch 486/500\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 0.3965 - accuracy: 0.8153 - val_loss: 0.4641 - val_accuracy: 0.7853\n",
            "Epoch 487/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3957 - accuracy: 0.8154 - val_loss: 0.4612 - val_accuracy: 0.7883\n",
            "Epoch 488/500\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 0.3958 - accuracy: 0.8139 - val_loss: 0.4460 - val_accuracy: 0.7933\n",
            "Epoch 489/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3959 - accuracy: 0.8138 - val_loss: 0.4485 - val_accuracy: 0.7973\n",
            "Epoch 490/500\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 0.3957 - accuracy: 0.8137 - val_loss: 0.4452 - val_accuracy: 0.7973\n",
            "Epoch 491/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3958 - accuracy: 0.8130 - val_loss: 0.4419 - val_accuracy: 0.7977\n",
            "Epoch 492/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3959 - accuracy: 0.8135 - val_loss: 0.4486 - val_accuracy: 0.7947\n",
            "Epoch 493/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3957 - accuracy: 0.8144 - val_loss: 0.4417 - val_accuracy: 0.7997\n",
            "Epoch 494/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3965 - accuracy: 0.8118 - val_loss: 0.4567 - val_accuracy: 0.7903\n",
            "Epoch 495/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3957 - accuracy: 0.8144 - val_loss: 0.4713 - val_accuracy: 0.7843\n",
            "Epoch 496/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3954 - accuracy: 0.8128 - val_loss: 0.4560 - val_accuracy: 0.7923\n",
            "Epoch 497/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3957 - accuracy: 0.8130 - val_loss: 0.4553 - val_accuracy: 0.7907\n",
            "Epoch 498/500\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 0.3959 - accuracy: 0.8153 - val_loss: 0.4665 - val_accuracy: 0.7873\n",
            "Epoch 499/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3952 - accuracy: 0.8154 - val_loss: 0.4577 - val_accuracy: 0.7923\n",
            "Epoch 500/500\n",
            "173/173 [==============================] - 1s 3ms/step - loss: 0.3958 - accuracy: 0.8141 - val_loss: 0.4403 - val_accuracy: 0.8023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gvl7VcgPoMp",
        "outputId": "d6a1112a-0812-4dd0-a1f7-4632c40f22f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "k1=rs.history['val_accuracy']\n",
        "print('The Validation Accuracy of ANN Model: ', np.mean(k1))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Validation Accuracy of ANN Model:  0.7846333322525024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQaSZFq-QJYV",
        "outputId": "c470de1e-b7d0-49c7-e471-f741b62f92c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "yp1= model1.predict(X_test)\n",
        "yp1"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.7898528 ],\n",
              "       [0.7161298 ],\n",
              "       [0.87722886],\n",
              "       ...,\n",
              "       [0.4988499 ],\n",
              "       [0.2099174 ],\n",
              "       [0.02417961]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNKt2B43QR6h"
      },
      "source": [
        "y_pred1 = []\n",
        "for element in yp1:\n",
        "    if element > 0.5:\n",
        "        y_pred1.append(1)\n",
        "    else:\n",
        "        y_pred1.append(0)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmh6hEksQXSs",
        "outputId": "9c22980a-7487-4da4-eb2c-f7614f9ed6c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "y_pred1"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SfJtkSeQYjQ",
        "outputId": "a44c0161-e6d8-40b5-e3ff-5b6bb7a39943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_labels1=np.unique(y_pred1, return_counts=True)\n",
        "y_pred_labels1"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([2135,  865]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYsWzv6PQjyw",
        "outputId": "a99c4dd2-f3bd-43b3-a806-8bf896532f02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_test_labels=np.unique(y_test, return_counts=True)\n",
        "y_test_labels"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1]), array([2380,  620]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9t4qmYxQr7Y",
        "outputId": "352e2116-6aa6-4aaa-e2ca-9423d880a89e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "c_m1 = confusion_matrix(y_test, y_pred1)\n",
        "c_m1"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1961,  419],\n",
              "       [ 174,  446]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xisJwQzQQ0vc",
        "outputId": "3b22ce7d-fe36-4748-fcbf-22732112fbb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize = (6,6))\n",
        "sns.heatmap(c_m1,cmap= \"Reds\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' )"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fcc773b14a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGQGXg0CRB3Q",
        "outputId": "2f0b45a3-728c-434d-fd0d-aefe4bcf14af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix , classification_report\n",
        "\n",
        "print(classification_report(y_test,y_pred1))\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.82      0.87      2380\n",
            "           1       0.52      0.72      0.60       620\n",
            "\n",
            "    accuracy                           0.80      3000\n",
            "   macro avg       0.72      0.77      0.73      3000\n",
            "weighted avg       0.84      0.80      0.81      3000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6iUULDKiRpqK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2KoF4RnRJgY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}